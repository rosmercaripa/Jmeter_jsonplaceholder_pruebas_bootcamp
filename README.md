# ‚ö° Simulaci√≥n de Pruebas de Performance sobre un Servicio P√∫blico de Consultas

Este proyecto consiste en la simulaci√≥n y an√°lisis de **pruebas de performance** sobre la API p√∫blica **[JSONPlaceholder](https://jsonplaceholder.typicode.com/)**, utilizando **Apache JMeter**.  
El objetivo es evaluar el comportamiento del servicio ante un escenario de carga que emule el uso de usuarios reales.

---

## üéØ Objetivo

- Configurar un **Plan de Pruebas en JMeter** para validar rendimiento de una API.  
- Simular **40 usuarios concurrentes** con ingreso progresivo y m√∫ltiples ciclos de ejecuci√≥n.  
- Evaluar m√©tricas clave: **tiempos de respuesta, throughput y porcentaje de errores**.  
- Analizar la **estabilidad del servicio** bajo carga controlada.  

---

## üõ†Ô∏è Configuraci√≥n del Plan de Pruebas

### 1. Thread Group
- N√∫mero de usuarios (Threads): **40**  
- Ramp-Up Period: **40 segundos** (un usuario por segundo).  
- Loop Count: **3 ciclos**  

### 2. Peticiones HTTP
Se configuraron **3 Samplers HTTP Request** con el servidor `jsonplaceholder.typicode.com`:

- **GET /posts** ‚Üí Listado de publicaciones.  
- **GET /comments** ‚Üí Listado de comentarios.  
- **GET /users** ‚Üí Listado de usuarios.  

### 3. Emulaci√≥n de Comportamiento Humano
- Se utiliz√≥ un **Gaussian Random Timer** con:
  - Retardo promedio: **1200 ms**
  - Desviaci√≥n est√°ndar: **400 ms**

Esto permite introducir pausas entre peticiones simulando la navegaci√≥n de un usuario real.  

### 4. Manejo de Sesiones y Cache
- **HTTP Cookie Manager**  
- **HTTP Cache Manager**  

Con esto se emula el comportamiento de un navegador real en cuanto a cookies y cache.  

### 5. Listeners Agregados
- **View Results Tree** (validaci√≥n de respuestas).  
- **Aggregate Report** (tiempo de respuesta, throughput y errores).  
- **Summary Report** (visi√≥n general de resultados).  

---

## ‚ñ∂Ô∏è Ejecuci√≥n de la Prueba

1. Abrir **Apache JMeter**.  
2. Configurar el plan de pruebas con los elementos mencionados.  
3. Ejecutar con el bot√≥n **Start** desde la interfaz GUI.  
4. Observar en tiempo real el rendimiento de las peticiones.  

---

## üìä An√°lisis de Resultados

Al finalizar la prueba, los reportes permiten responder:

- **Tiempo de respuesta promedio: 177**  
  Valor observado en **Summary report** (milisegundos).  

- **Errores detectados: 0.00%**  
  ¬øSe obtuvieron c√≥digos distintos de `200 OK`? ¬øCu√°l fue el **% de error** reportado?  

- **Throughput registrado:2.9/sec**  
  Promedio de **peticiones procesadas por segundo**.  

- **Estabilidad del servicio:**  
  Con base en los resultados, determinar si la API respondi√≥ de manera **estable** y consistente ante la carga de **40 usuarios concurrentes en 3 ciclos**.  

---

## üìñ Reflexi√≥n

Este ejercicio permiti√≥ aplicar los conocimientos de **pruebas de performance** en un entorno realista:  

- Se reforz√≥ la importancia de dise√±ar escenarios con **usuarios concurrentes y ramp-up progresivo**.  
- Se simul√≥ **comportamiento humano** mediante timers, evitando una carga artificial instant√°nea.  
- Se utiliz√≥ el manejo de **sesiones y cache** para reflejar la navegaci√≥n real en un navegador.  
- Los resultados obtenidos permiten evaluar si un **servicio p√∫blico como JSONPlaceholder** puede mantenerse estable bajo una carga moderada.  

---

## üë§ Autor

- [Tu Nombre]  
- QA Performance Tester | Automation Engineer  
- [LinkedIn](https://www.linkedin.com/) | [GitHub](https://github.com/TU_USUARIO)
